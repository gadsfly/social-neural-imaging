<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Social Neural Imaging | Qi Lab @ Duke</title>
    
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Instrument+Serif:ital@0;1&family=Source+Sans+3:ital,wght@0,300;0,400;0,500;0,600;1,400&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    
    <style>
        :root {
            --color-bg: #faf9f7;
            --color-bg-alt: #f0eeeb;
            --color-text: #1a1a1a;
            --color-text-muted: #555;
            --color-accent: #003366; /* Duke blue-ish */
            --color-accent-light: #e8eef4;
            --color-border: #ddd;
            --font-display: 'Instrument Serif', Georgia, serif;
            --font-body: 'Source Sans 3', -apple-system, sans-serif;
            --font-mono: 'JetBrains Mono', monospace;
            --max-width: 920px;
            --spacing-section: 5rem;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
        }

        body {
            font-family: var(--font-body);
            font-size: 17px;
            line-height: 1.7;
            color: var(--color-text);
            background: var(--color-bg);
            -webkit-font-smoothing: antialiased;
        }

        .container {
            max-width: var(--max-width);
            margin: 0 auto;
            padding: 0 2rem;
        }

        section {
            padding: var(--spacing-section) 0;
        }

        /* Typography */
        h1, h2, h3 {
            font-family: var(--font-display);
            font-weight: 400;
            line-height: 1.25;
        }

        h1 {
            font-size: clamp(2rem, 4.5vw, 2.8rem);
            letter-spacing: -0.01em;
            margin-bottom: 1.25rem;
        }

        h2 {
            font-size: 1.6rem;
            margin-bottom: 1.25rem;
            color: var(--color-accent);
            border-left: 3px solid var(--color-accent);
            padding-left: 0.75rem;
        }

        h3 {
            font-size: 1.15rem;
            margin-bottom: 0.75rem;
            margin-top: 1.5rem;
            color: var(--color-text);
        }

        p {
            margin-bottom: 1rem;
        }

        p:last-child {
            margin-bottom: 0;
        }

        a {
            color: var(--color-accent);
            text-decoration: underline;
            text-underline-offset: 3px;
            transition: opacity 0.2s;
        }

        a:hover {
            opacity: 0.7;
        }

        /* Navigation */
        nav {
            position: sticky;
            top: 0;
            background: rgba(250, 249, 247, 0.97);
            backdrop-filter: blur(10px);
            border-bottom: 1px solid var(--color-border);
            z-index: 100;
            padding: 0.9rem 0;
        }

        nav .container {
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 0.75rem;
        }

        nav .logo {
            font-family: var(--font-display);
            font-size: 1.1rem;
            text-decoration: none;
            color: var(--color-text);
            font-weight: 400;
        }

        nav ul {
            display: flex;
            gap: 1.5rem;
            list-style: none;
            flex-wrap: wrap;
        }

        nav a {
            text-decoration: none;
            font-size: 0.9rem;
            color: var(--color-text-muted);
            transition: color 0.2s;
        }

        nav a:hover {
            color: var(--color-accent);
            opacity: 1;
        }

        /* Hero */
        .hero {
            padding: 4rem 0 3rem;
            border-bottom: 1px solid var(--color-border);
        }

        .hero-label {
            font-size: 0.85rem;
            color: var(--color-text-muted);
            text-transform: uppercase;
            letter-spacing: 0.12em;
            margin-bottom: 0.75rem;
            font-weight: 500;
        }

        .hero-meta {
            margin-top: 1.5rem;
            padding-top: 1.5rem;
            border-top: 1px solid var(--color-border);
        }

        .hero-authors {
            font-size: 1.05rem;
            margin-bottom: 0.35rem;
        }

        .hero-affiliation {
            color: var(--color-text-muted);
            font-style: italic;
            font-size: 0.95rem;
        }

        .hero-links {
            display: flex;
            gap: 0.75rem;
            margin-top: 1.75rem;
            flex-wrap: wrap;
        }

        .btn {
            display: inline-flex;
            align-items: center;
            gap: 0.4rem;
            padding: 0.6rem 1.1rem;
            background: var(--color-accent);
            color: white;
            text-decoration: none;
            border-radius: 4px;
            font-weight: 500;
            font-size: 0.9rem;
            transition: transform 0.2s, box-shadow 0.2s;
        }

        .btn:hover {
            opacity: 1;
            transform: translateY(-1px);
            box-shadow: 0 4px 12px rgba(0, 51, 102, 0.25);
        }

        .btn-outline {
            background: transparent;
            color: var(--color-accent);
            border: 1.5px solid var(--color-accent);
        }

        .btn-outline:hover {
            background: var(--color-accent-light);
        }

        .btn svg {
            width: 16px;
            height: 16px;
        }

        .hero-note {
            margin-top: 1.25rem;
            font-size: 0.85rem;
            color: var(--color-text-muted);
            font-style: italic;
        }

        /* Abstract */
        .abstract {
            background: var(--color-bg-alt);
        }

        .abstract-text {
            font-size: 1.02rem;
            color: var(--color-text-muted);
            line-height: 1.75;
        }

        /* Stats grid */
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
            gap: 1rem;
            margin: 1.5rem 0;
        }

        .stat-card {
            background: white;
            padding: 1.25rem 1rem;
            border-radius: 6px;
            text-align: center;
            border: 1px solid var(--color-border);
        }

        .stat-number {
            font-family: var(--font-display);
            font-size: 2rem;
            color: var(--color-accent);
            line-height: 1;
            margin-bottom: 0.35rem;
        }

        .stat-label {
            font-size: 0.8rem;
            color: var(--color-text-muted);
            text-transform: uppercase;
            letter-spacing: 0.04em;
        }

        /* Figures */
        .figure {
            margin: 2rem 0;
        }

        .figure img {
            width: 100%;
            height: auto;
            border-radius: 6px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.08);
        }

        .figure-caption {
            margin-top: 0.75rem;
            font-size: 0.88rem;
            color: var(--color-text-muted);
            font-style: italic;
        }

        .figure-placeholder {
            width: 100%;
            aspect-ratio: 16/9;
            background: linear-gradient(135deg, var(--color-bg-alt) 0%, #e5e3df 100%);
            border-radius: 6px;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            color: var(--color-text-muted);
            font-size: 0.85rem;
            border: 2px dashed var(--color-border);
            text-align: center;
            padding: 2rem;
        }

        .figure-placeholder-icon {
            font-size: 2.5rem;
            margin-bottom: 0.75rem;
            opacity: 0.5;
        }

        /* Methods */
        .methods-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
            gap: 1.25rem;
            margin-top: 1.5rem;
        }

        .method-card {
            background: white;
            padding: 1.5rem;
            border-radius: 6px;
            border: 1px solid var(--color-border);
        }

        .method-card h3 {
            color: var(--color-accent);
            margin-top: 0;
            margin-bottom: 0.6rem;
            font-size: 1.05rem;
        }

        .method-card p {
            font-size: 0.92rem;
            color: var(--color-text-muted);
            margin: 0;
        }

        /* Directory tree */
        .directory-tree {
            background: #1e1e1e;
            color: #d4d4d4;
            padding: 1.25rem 1.5rem;
            border-radius: 6px;
            font-family: var(--font-mono);
            font-size: 0.8rem;
            line-height: 1.7;
            overflow-x: auto;
            margin: 1.5rem 0;
        }

        .directory-tree .folder {
            color: #4fc1ff;
        }

        .directory-tree .file {
            color: #9cdcfe;
        }

        .directory-tree .comment {
            color: #6a9955;
        }

        /* Table */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
            font-size: 0.92rem;
        }

        th, td {
            padding: 0.65rem 0.75rem;
            text-align: left;
            border-bottom: 1px solid var(--color-border);
        }

        th {
            font-weight: 600;
            background: var(--color-bg-alt);
        }

        td:nth-child(3) {
            color: var(--color-text-muted);
        }

        /* Poster section */
        .poster-embed {
            margin-top: 1.5rem;
        }

        .poster-embed img {
            width: 100%;
            height: auto;
            border: 1px solid var(--color-border);
            border-radius: 6px;
            cursor: pointer;
            transition: box-shadow 0.2s;
        }

        .poster-embed img:hover {
            box-shadow: 0 8px 30px rgba(0,0,0,0.12);
        }

        .poster-embed iframe {
            width: 100%;
            height: 600px;
            border: 1px solid var(--color-border);
            border-radius: 6px;
        }

        .poster-list {
            list-style: none;
            padding: 0;
        }

        .poster-list li {
            padding: 1rem 0;
            border-bottom: 1px solid var(--color-border);
        }

        .poster-list li:last-child {
            border-bottom: none;
        }

        .poster-list strong {
            color: var(--color-accent);
        }

        /* Citation */
        .citation-block {
            background: #1e1e1e;
            color: #d4d4d4;
            padding: 1.5rem;
            border-radius: 6px;
            margin-top: 1.25rem;
        }

        .citation-block pre {
            font-family: var(--font-mono);
            font-size: 0.82rem;
            white-space: pre-wrap;
            word-break: break-word;
            margin: 0;
        }

        .copy-btn {
            display: inline-flex;
            align-items: center;
            gap: 0.4rem;
            margin-top: 1rem;
            padding: 0.45rem 0.9rem;
            background: #2d2d2d;
            border: 1px solid #444;
            border-radius: 4px;
            font-family: var(--font-body);
            font-size: 0.8rem;
            color: #ccc;
            cursor: pointer;
            transition: background 0.2s;
        }

        .copy-btn:hover {
            background: #3d3d3d;
        }

        /* About section */
        .about-content {
            display: grid;
            grid-template-columns: 1fr;
            gap: 1.5rem;
        }

        @media (min-width: 640px) {
            .about-content {
                grid-template-columns: 2fr 1fr;
            }
        }

        .contact-card {
            background: white;
            padding: 1.5rem;
            border-radius: 6px;
            border: 1px solid var(--color-border);
        }

        .contact-card h3 {
            margin-top: 0;
            font-size: 1rem;
        }

        .contact-links {
            display: flex;
            flex-direction: column;
            gap: 0.5rem;
            font-size: 0.92rem;
        }

        /* Footer */
        footer {
            padding: 2rem 0;
            border-top: 1px solid var(--color-border);
            text-align: center;
            color: var(--color-text-muted);
            font-size: 0.85rem;
        }

        /* Section backgrounds */
        .alt-bg {
            background: var(--color-bg-alt);
        }

        /* Responsive */
        @media (max-width: 640px) {
            :root {
                --spacing-section: 3.5rem;
            }

            nav ul {
                gap: 1rem;
            }

            .hero-links {
                flex-direction: column;
            }

            .btn {
                justify-content: center;
            }
        }

        /* Animations */
        @keyframes fadeUp {
            from {
                opacity: 0;
                transform: translateY(15px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .hero > * {
            animation: fadeUp 0.6s ease-out forwards;
            opacity: 0;
        }

        .hero > *:nth-child(1) { animation-delay: 0.05s; }
        .hero > *:nth-child(2) { animation-delay: 0.1s; }
        .hero > *:nth-child(3) { animation-delay: 0.15s; }
        .hero > *:nth-child(4) { animation-delay: 0.2s; }
    </style>
</head>
<body>
    <nav>
        <div class="container">
            <a href="#" class="logo">Social Neural Imaging</a>
            <ul>
                <li><a href="#abstract">Abstract</a></li>
                <li><a href="#dataset">Dataset</a></li>
                <li><a href="#methods">Methods</a></li>
                <li><a href="#poster">Poster</a></li>
                <li><a href="#citation">Cite</a></li>
                <li><a href="#about">About</a></li>
            </ul>
        </div>
    </nav>

    <section class="hero">
        <div class="container">
            <div class="hero-label">Multi-Modal Neuroscience Dataset</div>
            
            <h1>A Scalable System for Social Neural Imaging: Integrating Multi-animal 3D Pose Tracking and Ca¬≤‚Å∫ Imaging in Freely Interacting Animals</h1>
            
            <div class="hero-meta">
                <p class="hero-authors">
                    <strong>Lingxuan Qi</strong>, Renzhi Zhan, Tianqing Li, Anshuman Sabath, Joshua H. Wu, Timothy W. Dunn
                </p>
                <p class="hero-affiliation">
                    Department of Biomedical Engineering, Duke University
                </p>
            </div>

            <div class="hero-links">
                <a href="poster_sfn_2025.pdf" class="btn" target="_blank">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
                    </svg>
                    Poster (SfN 2024)
                </a>
                <a href="https://github.com/YOUR_USERNAME/bbop" class="btn btn-outline" target="_blank">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4" />
                    </svg>
                    Code (GitHub)
                </a>
                <a href="#dataset" class="btn btn-outline">
                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4l-4 4m0 0l-4-4m4 4V4" />
                    </svg>
                    Dataset
                </a>
                <!-- Uncomment when preprint is ready:
                <a href="https://arxiv.org/abs/XXXX.XXXXX" class="btn btn-outline" target="_blank">
                    Preprint
                </a>
                -->
            </div>

            <p class="hero-note">
                Data release and preprint in preparation.
            </p>
        </div>
    </section>

    <section id="abstract" class="abstract">
        <div class="container">
            <h2>Abstract</h2>
            <p class="abstract-text">
                Naturalistic social behavior emerges from interactions between distributed neural circuits and richly structured environments. Yet most publicly available resources either provide neural activity under highly constrained tasks or large-scale pose tracking without simultaneous neural recordings. We present a multi-modal dataset combining one-photon calcium imaging, six-camera 3D pose estimation, and rich metadata from freely behaving mice in a 1 m open arena. Adult male C57BL/6J mice explored the arena alone or in pairs while behavior was recorded at 30 Hz by six synchronized cameras. In a subset of sessions, layer 2/3 activity in visual cortex (V1) or motor/premotor cortex (M1/PMC) was recorded with a UCLA Miniscope V4. The current release comprises approximately 50 mice, 116 recording sessions, and 22 hours of video. For each session we provide raw multi-camera videos, 3D keypoint trajectories, calcium traces with ŒîF/F normalization, and structured metadata. Preprocessing, synchronization, and quality control are implemented by an open-source pipeline (BBOP) with PyArrow/Parquet logs. This resource supports studies of naturalistic social behavior, neural encoding of spatial and social variables, and multi-animal pose estimation benchmarks.
            </p>
        </div>
    </section>

    <section id="motivation">
        <div class="container">
            <h2>Background & Motivation</h2>
            
            <p>
                <strong>Prior work:</strong> social-DANNCE (sDANNCE) has mapped rich social behavior in rats, enabling detailed 3D kinematic analysis of freely interacting animals.
            </p>
            
            <p>
                <strong>The gap:</strong> Mice add unique challenges‚Äîsmaller scale, more occlusion, identity confusion‚Äîplus head-mounted imaging constraints. Cortical-surface calcium imaging remains particularly challenging in freely moving, socially interacting animals.
            </p>
            
            <p>
                <strong>This work:</strong> We combine six-camera sDANNCE-style tracking with Miniscope V4 one-photon imaging through chronic cranial windows, enabling simultaneous neural and behavioral recording during unconstrained social interaction.
            </p>
            
            <p>
                <strong>Payoff:</strong> Quantitative 3D kinematics paired with stable ŒîF/F signals from V1 and PMC/M1 opens the door to naturalistic social neurobehavior studies‚Äîasking how visual and motor circuits encode edge distance, partner proximity, and approach/escape dynamics.
            </p>

            <div class="figure">
                <!-- TODO: Add system schematic from poster -->
                <div class="figure-placeholder">
                    <div class="figure-placeholder-icon">üî¨</div>
                    <p><strong>System Schematic</strong></p>
                    <p>Extract from poster: 6-camera setup + miniscope + arena diagram</p>
                </div>
                <p class="figure-caption">
                    Recording setup showing six synchronized FLIR cameras at three elevations, automated tether system, and UCLA Miniscope V4 integration.
                </p>
            </div>
        </div>
    </section>

    <section id="dataset" class="alt-bg">
        <div class="container">
            <h2>Dataset Overview</h2>

            <div class="stats-grid">
                <div class="stat-card">
                    <div class="stat-number">116</div>
                    <div class="stat-label">Sessions</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">~50</div>
                    <div class="stat-label">Subjects</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">22h</div>
                    <div class="stat-label">Video</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">6</div>
                    <div class="stat-label">Cameras</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">35</div>
                    <div class="stat-label">Social Sessions</div>
                </div>
            </div>

            <p>Each session includes raw six-camera videos (30 Hz), 3D center-of-mass trajectories, full-body 3D keypoints, and structured metadata. For neural sessions, we provide motion-corrected calcium traces with ŒîF/F normalization and frame-level synchronization to behavior.</p>

            <table>
                <thead>
                    <tr>
                        <th>Component</th>
                        <th>Count</th>
                        <th>Details</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Subjects</td>
                        <td>~50</td>
                        <td>Adult male C57BL/6J</td>
                    </tr>
                    <tr>
                        <td>Total sessions</td>
                        <td>116</td>
                        <td>~22 hours total</td>
                    </tr>
                    <tr>
                        <td>Behavior-only</td>
                        <td>67</td>
                        <td>Multi-camera video + 3D pose</td>
                    </tr>
                    <tr>
                        <td>Neural + behavior</td>
                        <td>49</td>
                        <td>Video + pose + Ca¬≤‚Å∫ imaging</td>
                    </tr>
                    <tr>
                        <td>Single-animal</td>
                        <td>22</td>
                        <td>Solo exploration sessions</td>
                    </tr>
                    <tr>
                        <td>Social pairs</td>
                        <td>35</td>
                        <td>Two-mouse interaction sessions</td>
                    </tr>
                </tbody>
            </table>

            <div class="figure">
                <!-- TODO: Add arena/behavior figure from poster -->
                <div class="figure-placeholder">
                    <div class="figure-placeholder-icon">üê≠</div>
                    <p><strong>Arena & Behavior</strong></p>
                    <p>Extract from poster: Arena photos + spatial occupancy heatmaps + trajectory examples</p>
                </div>
                <p class="figure-caption">
                    The 1 m circular arena enables long-range trajectories and rich turning patterns. Spatial occupancy maps show exploration patterns for individual mice and co-occupancy during social sessions.
                </p>
            </div>
        </div>
    </section>

    <section id="pipeline">
        <div class="container">
            <h2>BBOP Pipeline</h2>
            
            <p>
                The Bryan Building Open Field Pipeline (BBOP) handles acquisition, synchronization, pose estimation, and neural preprocessing with automated quality control and structured logging.
            </p>

            <div class="figure">
                <!-- TODO: Add pipeline flowchart from poster -->
                <div class="figure-placeholder">
                    <div class="figure-placeholder-icon">‚öôÔ∏è</div>
                    <p><strong>Pipeline Flowchart</strong></p>
                    <p>Extract from poster: BBOP pipeline diagram showing Scan ‚Üí Filter ‚Üí Execute stages</p>
                </div>
            </div>

            <h3>Pipeline Highlights</h3>
            <ul style="margin-left: 1.5rem; margin-top: 0.5rem;">
                <li><strong>Scan:</strong> Flags processing status across all recordings</li>
                <li><strong>Filter:</strong> Selects recordings for specific pipeline stages</li>
                <li><strong>Execute:</strong> Sync ‚Üí Predict ‚Üí Align workflow with parallel processing</li>
            </ul>

            <h3 style="margin-top: 2rem;">Data Organization</h3>

            <div class="directory-tree">
<span class="folder">dataset_root/</span>
‚îú‚îÄ‚îÄ <span class="folder">beh/</span>                     <span class="comment"># behavior-only sessions</span>
‚îÇ   ‚îî‚îÄ‚îÄ <span class="folder">rec_path/</span>
‚îÇ       ‚îú‚îÄ‚îÄ <span class="folder">metadata/</span>        <span class="comment"># session metadata, frame mappings</span>
‚îÇ       ‚îî‚îÄ‚îÄ <span class="folder">annotations/</span>     <span class="comment"># com3d.mat, pose3d_mouse*.mat</span>
‚îî‚îÄ‚îÄ <span class="folder">mini/</span>                    <span class="comment"># miniscope sessions</span>
    ‚îú‚îÄ‚îÄ <span class="folder">single/</span>              <span class="comment"># single-animal recordings</span>
    ‚îî‚îÄ‚îÄ <span class="folder">social/</span>              <span class="comment"># social pair recordings</span>
        ‚îî‚îÄ‚îÄ <span class="folder">rec_path/</span>
            ‚îú‚îÄ‚îÄ <span class="folder">miniscope/</span>
            ‚îÇ   ‚îú‚îÄ‚îÄ <span class="file">miniscope.nc</span>       <span class="comment"># motion-corrected Ca¬≤‚Å∫ data</span>
            ‚îÇ   ‚îî‚îÄ‚îÄ <span class="file">timeStamps.csv</span>     <span class="comment"># frame timestamps</span>
            ‚îú‚îÄ‚îÄ <span class="folder">metadata/</span>
            ‚îÇ   ‚îî‚îÄ‚îÄ <span class="file">frame_mapping.json</span> <span class="comment"># miniscope ‚Üî camera mapping</span>
            ‚îî‚îÄ‚îÄ <span class="folder">annotations/</span>
                ‚îú‚îÄ‚îÄ <span class="file">pose3d_mouse1.mat</span>  <span class="comment"># 3D keypoints per mouse</span>
                ‚îî‚îÄ‚îÄ <span class="file">com3d.mat</span>          <span class="comment"># center-of-mass trajectories</span>
            </div>
        </div>
    </section>

    <section id="methods" class="alt-bg">
        <div class="container">
            <h2>Methods</h2>

            <div class="methods-grid">
                <div class="method-card">
                    <h3>üß¨ Viral Targeting</h3>
                    <p>
                        AAV1-hSyn-Soma-jGCaMP8s injected into layer 2/3 of V1 (AP ‚àí3.5, ML 2.5, DV 0.25 mm) or M1/PMC. Animals recovered 4‚Äì5 weeks before window construction.
                    </p>
                </div>
                <div class="method-card">
                    <h3>üî¨ Cranial Windows</h3>
                    <p>
                        ~1 mm diameter window over injection site, sealed with glass coverslip and dental cement. UCLA Miniscope V4 baseplate aligned and fixed after recovery.
                    </p>
                </div>
                <div class="method-card">
                    <h3>üìπ Multi-Camera Recording</h3>
                    <p>
                        Six FLIR ORX-10G cameras at 30 Hz via 10 GigE. Three vertical elevations with opposing camera pairs maximize coverage and reduce occlusions.
                    </p>
                </div>
                <div class="method-card">
                    <h3>üîó Synchronization</h3>
                    <p>
                        Hardware trigger + LED brightness protocol. Auxiliary webcam captures arena lights and miniscope LED flicker for cross-timebase alignment.
                    </p>
                </div>
                <div class="method-card">
                    <h3>ü¶¥ 3D Pose Estimation</h3>
                    <p>
                        sDANNCE predicts 3D keypoints from volumetric reconstructions. Automated QC flags sessions with trajectory artifacts or identity swaps.
                    </p>
                </div>
                <div class="method-card">
                    <h3>üß† Ca¬≤‚Å∫ Preprocessing</h3>
                    <p>
                        Minian/CNMF-based pipeline: motion correction, source extraction, ŒîF/F with percentile baseline. Optional cross-session ROI matching.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <section id="results">
        <div class="container">
            <h2>Aligned Neural-Behavioral Data</h2>
            
            <p>
                With synchronized 3D pose and calcium imaging, we can analyze neural activity in the context of precise spatial and social variables. Example analyses include correlating V1 activity with visual cone reconstructions based on estimated eye positions, and clustering unsupervised behavioral motifs from 3D kinematics.
            </p>

            <div class="figure">
                <!-- TODO: Add aligned data figure from poster -->
                <div class="figure-placeholder">
                    <div class="figure-placeholder-icon">üìä</div>
                    <p><strong>Aligned Data Examples</strong></p>
                    <p>Extract from poster: Neural traces + behavior events + UMAP clusters</p>
                </div>
                <p class="figure-caption">
                    Left: Clustered neuron activity aligned to social interaction events. Right: Unsupervised behavior clusters from 3D pose embeddings, with labels including static, locomotion, and social behaviors.
                </p>
            </div>
        </div>
    </section>

    <section id="poster" class="alt-bg">
        <div class="container">
            <h2>Posters & Presentations</h2>
            
            <ul class="poster-list">
                <li>
                    <strong>SfN 2024</strong> ‚Äî "A Scalable System for Social Neural Imaging: Integrating Multi-animal 3D Pose Tracking and Ca¬≤‚Å∫ Imaging in Freely Interacting Animals"
                    <br>
                    <a href="poster_sfn_2025.pdf" target="_blank">Download poster (PDF)</a>
                </li>
                <li>
                    <strong>BMES 2024</strong> ‚Äî [Title TBD]
                    <br>
                    <a href="poster_bmes_2024.pdf" target="_blank">Download poster (PDF)</a>
                </li>
            </ul>

            <div class="poster-embed">
                <!-- Option 1: Embedded PDF viewer -->
                <!-- <iframe src="poster_sfn_2025.pdf" title="SfN 2024 Poster"></iframe> -->
                
                <!-- Option 2: Clickable thumbnail (recommended) -->
                <!-- TODO: Generate a PNG thumbnail of the poster and link to PDF -->
                <a href="poster_sfn_2025.pdf" target="_blank">
                    <div class="figure-placeholder" style="aspect-ratio: 42/72; max-width: 400px;">
                        <div class="figure-placeholder-icon">üìÑ</div>
                        <p><strong>Click to view poster</strong></p>
                        <p>SfN 2024 (42" √ó 72")</p>
                    </div>
                </a>
            </div>
        </div>
    </section>

    <section id="citation">
        <div class="container">
            <h2>Citation</h2>
            
            <p>If you use this dataset or pipeline in your research, please cite:</p>

            <div class="citation-block">
                <pre>@article{qi2025social,
    author = {Qi, Lingxuan and Zhan, Renzhi and Li, Tianqing and 
              Sabath, Anshuman and Wu, Joshua H. and Dunn, Timothy W.},
    title = {A Scalable System for Social Neural Imaging: Integrating 
             Multi-animal 3D Pose Tracking and Ca¬≤‚Å∫ Imaging in 
             Freely Interacting Animals},
    journal = {In preparation},
    year = {2025}
}</pre>
                <button class="copy-btn" onclick="copyBibtex()">
                    <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z" />
                    </svg>
                    Copy BibTeX
                </button>
            </div>
        </div>
    </section>

    <section id="about" class="alt-bg">
        <div class="container">
            <h2>About</h2>
            
            <div class="about-content">
                <div>
                    <p>
                        This project is part of ongoing work in the <a href="https://dunn.pratt.duke.edu/" target="_blank">Dunn Lab</a> at Duke University. Our goal is to understand how cortical populations in visual and motor areas encode spatial layout, boundary distance, and social interaction structure during unconstrained behavior.
                    </p>
                    <p>
                        The dataset and BBOP pipeline are designed to support studies of naturalistic social behavior, neural encoding of spatial and social variables, and multi-animal pose estimation benchmarks.
                    </p>
                </div>
                
                <div class="contact-card">
                    <h3>Contact</h3>
                    <div class="contact-links">
                        <a href="mailto:lingxuan.qi@duke.edu">lingxuan.qi@duke.edu</a>
                        <a href="https://github.com/YOUR_USERNAME" target="_blank">GitHub</a>
                        <a href="cv.pdf" target="_blank">CV (PDF)</a>
                        <!-- <a href="https://scholar.google.com/..." target="_blank">Google Scholar</a> -->
                    </div>
                </div>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <p>
                ¬© 2025 Lingxuan Qi ¬∑ Duke University ¬∑ 
                <a href="https://dunn.pratt.duke.edu/" target="_blank">Dunn Lab</a>
            </p>
        </div>
    </footer>

    <script>
        function copyBibtex() {
            const bibtex = `@article{qi2025social,
    author = {Qi, Lingxuan and Zhan, Renzhi and Li, Tianqing and Sabath, Anshuman and Wu, Joshua H. and Dunn, Timothy W.},
    title = {A Scalable System for Social Neural Imaging: Integrating Multi-animal 3D Pose Tracking and Ca¬≤‚Å∫ Imaging in Freely Interacting Animals},
    journal = {In preparation},
    year = {2025}
}`;
            navigator.clipboard.writeText(bibtex);
            
            const btn = document.querySelector('.copy-btn');
            const originalHTML = btn.innerHTML;
            btn.innerHTML = '‚úì Copied!';
            setTimeout(() => {
                btn.innerHTML = originalHTML;
            }, 2000);
        }

        // Smooth scroll for nav links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });
    </script>
</body>
</html>
